{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavithabakshi/ADNI/blob/master/ADNI_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFQZjum0So-D",
        "colab_type": "code",
        "outputId": "1dbcf702-4ed0-41ef-fb96-f00a13f3cc08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "metadata_test = 'https://raw.githubusercontent.com/kavithabakshi/ADNI/master/ADNI_Metadata_test.csv'\n",
        "metadata = 'https://raw.githubusercontent.com/kavithabakshi/ADNI/master/ADNI_Metadata.csv'\n",
        "df = pd.read_csv(metadata, sep='\\s*,\\s*',delimiter = ',')\n",
        "print(df.shape)\n",
        "df_test = pd.read_csv(metadata_test, sep='\\s*,\\s*',delimiter = ',')\n",
        "print(df_test.shape)\n",
        "df_cn=df[df['researchGroup']==\"CN\"]\n",
        "print(df_cn.shape)\n",
        "df_ad=df[df['researchGroup']==\"AD\"]\n",
        "print(df_ad.shape)\n",
        "df_mci=df[df['researchGroup']==\"MCI\"]\n",
        "print(df_mci.shape)\n",
        "df.info()\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 9)\n",
            "(688, 9)\n",
            "(490, 9)\n",
            "(332, 9)\n",
            "(777, 9)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 9 columns):\n",
            "researchGroup    1599 non-null object\n",
            "subjectSex       1599 non-null object\n",
            "MMSCORE          1599 non-null int64\n",
            "GDTOTAL          1599 non-null int64\n",
            "CDGLOBAL         1599 non-null float64\n",
            "NPISCORE         1599 non-null int64\n",
            "FAQTOTAL         1599 non-null int64\n",
            "subjectAge       1599 non-null float64\n",
            "weightKg         1599 non-null float64\n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 112.5+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "researchGroup    0\n",
              "subjectSex       0\n",
              "MMSCORE          0\n",
              "GDTOTAL          0\n",
              "CDGLOBAL         0\n",
              "NPISCORE         0\n",
              "FAQTOTAL         0\n",
              "subjectAge       0\n",
              "weightKg         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMboWsmOae1n",
        "colab_type": "code",
        "outputId": "c61c003b-c0f3-4a6f-e4da-8ad5b5871aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "print(df.columns)\n",
        "y = df['researchGroup']\n",
        "print(y.shape)\n",
        "X = df.drop(['researchGroup'], axis=1)\n",
        "print(X.shape)\n",
        "X = pd.get_dummies(data = X, columns = ['subjectSex'] , prefix = ['subjectSex'] , drop_first = True)\n",
        "print(X.shape, '\\n', X.columns)\n",
        "X.head()\n",
        "y = pd.get_dummies(data = y, columns = ['researchGroup'] , prefix = ['researchGroup'] , drop_first = True)\n",
        "print(y.shape, '\\n', y.columns)\n",
        "y.head()\n",
        "print(df_test.columns)\n",
        "y_test = df_test['researchGroup']\n",
        "print(y_test.shape)\n",
        "X_test = df_test.drop(['researchGroup'], axis=1)\n",
        "print(X_test.shape)\n",
        "X_test = pd.get_dummies(data = X_test, columns = ['subjectSex'] , prefix = ['subjectSex'] , drop_first = True)\n",
        "print(X_test.shape, '\\n', X_test.columns)\n",
        "X_test.head()\n",
        "y_test1 = pd.get_dummies(data = y_test, columns = ['researchGroup'] , prefix = ['researchGroup'] , drop_first = True)\n",
        "#print(y_test.shape, '\\n', y.columns)\n",
        "#y.head()\n",
        "lentest = y_test.shape\n",
        "lentest1 = lentest[0] - 1\n",
        "print(lentest1)\n",
        "for i in range(lentest1):\n",
        "  if (y_test[i] == \"CN\"):\n",
        "    y_test[i] = 0\n",
        "  elif (y_test[i] == \"MCI\"):\n",
        "    y_test[i] = 1\n",
        "  else:\n",
        "    y_test[i] = 2\n",
        "print(y_test.head())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['researchGroup', 'subjectSex', 'MMSCORE', 'GDTOTAL', 'CDGLOBAL',\n",
            "       'NPISCORE', 'FAQTOTAL', 'subjectAge', 'weightKg'],\n",
            "      dtype='object')\n",
            "(1599,)\n",
            "(1599, 8)\n",
            "(1599, 8) \n",
            " Index(['MMSCORE', 'GDTOTAL', 'CDGLOBAL', 'NPISCORE', 'FAQTOTAL', 'subjectAge',\n",
            "       'weightKg', 'subjectSex_M'],\n",
            "      dtype='object')\n",
            "(1599, 2) \n",
            " Index(['['researchGroup']_CN', '['researchGroup']_MCI'], dtype='object')\n",
            "Index(['researchGroup', 'subjectSex', 'MMSCORE', 'GDTOTAL', 'CDGLOBAL',\n",
            "       'NPISCORE', 'FAQTOTAL', 'subjectAge', 'weightKg'],\n",
            "      dtype='object')\n",
            "(688,)\n",
            "(688, 8)\n",
            "(688, 8) \n",
            " Index(['MMSCORE', 'GDTOTAL', 'CDGLOBAL', 'NPISCORE', 'FAQTOTAL', 'subjectAge',\n",
            "       'weightKg', 'subjectSex_M'],\n",
            "      dtype='object')\n",
            "687\n",
            "0    2\n",
            "1    2\n",
            "2    2\n",
            "3    2\n",
            "4    2\n",
            "Name: researchGroup, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URjO04qQgClC",
        "colab_type": "code",
        "outputId": "5f2bb09f-45c0-4f6c-d292-8332306944c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "from tensorflow.python.layers import base\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "from keras.layers import Dense, Input, Embedding, Reshape, Dropout\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO2phcDKgFLl",
        "colab_type": "code",
        "outputId": "3bc76b4d-e127-47c5-80b1-d16af3af104e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3027
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, auc, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "droprate = 0.4\n",
        "model = Sequential()\n",
        "model.add(Dense(160, input_dim=8, activation='sigmoid'))\n",
        "model.add(Dropout(droprate))\n",
        "model.add(Dense(108, activation='sigmoid'))\n",
        "model.add(Dropout(droprate))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X,y, epochs = 75)\n",
        "y_pred = model.predict(X_test)\n",
        "lenPred= y_pred.shape\n",
        "#y_pred = [\"CN\" if x[0] > 0.5 elif x[1] > 0.5 \"MCI\" else \"AD\"  for x in y_pred]\n",
        "y_pred1 = [x for x in y_pred]\n",
        "lenPred1 = lenPred[0] - 1\n",
        "print(lenPred1)\n",
        "for i in range(lenPred1):\n",
        "  if (y_pred[i][0] > 0.5):\n",
        "    y_pred1[i] = 0\n",
        "  elif (y_pred[i][1] > 0.5):\n",
        "    y_pred1[i] = 1\n",
        "  else:\n",
        "    y_pred1[i] = 2\n",
        "score = 0\n",
        "for i in range(lenPred1):\n",
        "  if (y_pred[i] == y_test[i]):\n",
        "    score = score + 1\n",
        "accuracy = (score/(lenPred1+1))*100\n",
        "print(accuracy)\n",
        "eval = model.evaluate(X_test, y_test1)\n",
        "print(eval)\n",
        "#dnn_score=round(accuracy_score(y_test, y_pred1) * 100,2)\n",
        "#print(Title,'Dataset test accuracy_score',dnn_score)\n",
        "#print(classification_report(y_test_balanced, y_pred))\n",
        " \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1599/1599 [==============================] - 2s 1ms/step - loss: 0.6899 - acc: 0.5897\n",
            "Epoch 2/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.6462 - acc: 0.6082\n",
            "Epoch 3/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.6185 - acc: 0.6141\n",
            "Epoch 4/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.5855 - acc: 0.6451\n",
            "Epoch 5/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.5631 - acc: 0.6632\n",
            "Epoch 6/75\n",
            "1599/1599 [==============================] - 0s 73us/step - loss: 0.5434 - acc: 0.6973\n",
            "Epoch 7/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.5313 - acc: 0.7033\n",
            "Epoch 8/75\n",
            "1599/1599 [==============================] - 0s 78us/step - loss: 0.5170 - acc: 0.7161\n",
            "Epoch 9/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.5037 - acc: 0.7301\n",
            "Epoch 10/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.4850 - acc: 0.7486\n",
            "Epoch 11/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.4660 - acc: 0.7705\n",
            "Epoch 12/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.4790 - acc: 0.7527\n",
            "Epoch 13/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.4526 - acc: 0.7792\n",
            "Epoch 14/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.4323 - acc: 0.7936\n",
            "Epoch 15/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.4495 - acc: 0.7795\n",
            "Epoch 16/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.4188 - acc: 0.8077\n",
            "Epoch 17/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.4121 - acc: 0.8068\n",
            "Epoch 18/75\n",
            "1599/1599 [==============================] - 0s 73us/step - loss: 0.4020 - acc: 0.8180\n",
            "Epoch 19/75\n",
            "1599/1599 [==============================] - 0s 73us/step - loss: 0.3866 - acc: 0.8280\n",
            "Epoch 20/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.3895 - acc: 0.8215\n",
            "Epoch 21/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.3655 - acc: 0.8346\n",
            "Epoch 22/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.3515 - acc: 0.8502\n",
            "Epoch 23/75\n",
            "1599/1599 [==============================] - 0s 73us/step - loss: 0.3509 - acc: 0.8480\n",
            "Epoch 24/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.3431 - acc: 0.8533\n",
            "Epoch 25/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.3422 - acc: 0.8568\n",
            "Epoch 26/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.3155 - acc: 0.8677\n",
            "Epoch 27/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.3116 - acc: 0.8712\n",
            "Epoch 28/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.3047 - acc: 0.8743\n",
            "Epoch 29/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.3000 - acc: 0.8809\n",
            "Epoch 30/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2894 - acc: 0.8884\n",
            "Epoch 31/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2865 - acc: 0.8893\n",
            "Epoch 32/75\n",
            "1599/1599 [==============================] - 0s 78us/step - loss: 0.2748 - acc: 0.8899\n",
            "Epoch 33/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2766 - acc: 0.8896\n",
            "Epoch 34/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2703 - acc: 0.8984\n",
            "Epoch 35/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2779 - acc: 0.8931\n",
            "Epoch 36/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2573 - acc: 0.9003\n",
            "Epoch 37/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2572 - acc: 0.8993\n",
            "Epoch 38/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2526 - acc: 0.9071\n",
            "Epoch 39/75\n",
            "1599/1599 [==============================] - 0s 71us/step - loss: 0.2530 - acc: 0.9068\n",
            "Epoch 40/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2327 - acc: 0.9199\n",
            "Epoch 41/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2468 - acc: 0.9065\n",
            "Epoch 42/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2546 - acc: 0.9024\n",
            "Epoch 43/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2309 - acc: 0.9168\n",
            "Epoch 44/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2354 - acc: 0.9215\n",
            "Epoch 45/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2264 - acc: 0.9262\n",
            "Epoch 46/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2256 - acc: 0.9215\n",
            "Epoch 47/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2236 - acc: 0.9215\n",
            "Epoch 48/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2103 - acc: 0.9259\n",
            "Epoch 49/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2220 - acc: 0.9281\n",
            "Epoch 50/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2149 - acc: 0.9268\n",
            "Epoch 51/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2203 - acc: 0.9231\n",
            "Epoch 52/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2125 - acc: 0.9246\n",
            "Epoch 53/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2276 - acc: 0.9209\n",
            "Epoch 54/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2071 - acc: 0.9293\n",
            "Epoch 55/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2064 - acc: 0.9256\n",
            "Epoch 56/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2061 - acc: 0.9281\n",
            "Epoch 57/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.2024 - acc: 0.9321\n",
            "Epoch 58/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.1969 - acc: 0.9312\n",
            "Epoch 59/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2202 - acc: 0.9284\n",
            "Epoch 60/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2002 - acc: 0.9321\n",
            "Epoch 61/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.1991 - acc: 0.9375\n",
            "Epoch 62/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.1961 - acc: 0.9325\n",
            "Epoch 63/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2036 - acc: 0.9331\n",
            "Epoch 64/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.2001 - acc: 0.9334\n",
            "Epoch 65/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2018 - acc: 0.9318\n",
            "Epoch 66/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.2019 - acc: 0.9315\n",
            "Epoch 67/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2087 - acc: 0.9331\n",
            "Epoch 68/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2034 - acc: 0.9309\n",
            "Epoch 69/75\n",
            "1599/1599 [==============================] - 0s 77us/step - loss: 0.1995 - acc: 0.9368\n",
            "Epoch 70/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.1932 - acc: 0.9375\n",
            "Epoch 71/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.2068 - acc: 0.9309\n",
            "Epoch 72/75\n",
            "1599/1599 [==============================] - 0s 74us/step - loss: 0.1939 - acc: 0.9346\n",
            "Epoch 73/75\n",
            "1599/1599 [==============================] - 0s 79us/step - loss: 0.1918 - acc: 0.9346\n",
            "Epoch 74/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.1991 - acc: 0.9365\n",
            "Epoch 75/75\n",
            "1599/1599 [==============================] - 0s 76us/step - loss: 0.1950 - acc: 0.9365\n",
            "687\n",
            "14.970930232558139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-123f525dc28d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenPred1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#dnn_score=round(accuracy_score(y_test, y_pred1) * 100,2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_57 to have shape (2,) but got array with shape (3,)"
          ]
        }
      ]
    }
  ]
}