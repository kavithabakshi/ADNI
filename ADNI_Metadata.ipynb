{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavithabakshi/ADNI/blob/master/ADNI_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFQZjum0So-D",
        "colab_type": "code",
        "outputId": "f604ee86-7874-4dff-f841-4b342ca321af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "metadata_test = 'https://raw.githubusercontent.com/kavithabakshi/ADNI/master/ADNI_Metadata_test.csv'\n",
        "metadata = 'https://raw.githubusercontent.com/kavithabakshi/ADNI/master/ADNI_Metadata.csv'\n",
        "df = pd.read_csv(metadata, sep='\\s*,\\s*',delimiter = ',')\n",
        "print(df.shape)\n",
        "df_test = pd.read_csv(metadata_test, sep='\\s*,\\s*',delimiter = ',')\n",
        "print(df_test.shape)\n",
        "df_cn=df[df['researchGroup']==\"CN\"]\n",
        "print(df_cn.shape)\n",
        "df_ad=df[df['researchGroup']==\"AD\"]\n",
        "print(df_ad.shape)\n",
        "df_mci=df[df['researchGroup']==\"MCI\"]\n",
        "print(df_mci.shape)\n",
        "df.info()\n",
        "df.isnull().sum()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1599, 9)\n",
            "(688, 9)\n",
            "(490, 9)\n",
            "(332, 9)\n",
            "(777, 9)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 9 columns):\n",
            "researchGroup    1599 non-null object\n",
            "subjectSex       1599 non-null object\n",
            "MMSCORE          1599 non-null int64\n",
            "GDTOTAL          1599 non-null int64\n",
            "CDGLOBAL         1599 non-null float64\n",
            "NPISCORE         1599 non-null int64\n",
            "FAQTOTAL         1599 non-null int64\n",
            "subjectAge       1599 non-null float64\n",
            "weightKg         1599 non-null float64\n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 112.5+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "researchGroup    0\n",
              "subjectSex       0\n",
              "MMSCORE          0\n",
              "GDTOTAL          0\n",
              "CDGLOBAL         0\n",
              "NPISCORE         0\n",
              "FAQTOTAL         0\n",
              "subjectAge       0\n",
              "weightKg         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMboWsmOae1n",
        "colab_type": "code",
        "outputId": "cf80cf36-1db2-452f-8af9-a7b67e368299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "print(df.columns)\n",
        "y = df['researchGroup']\n",
        "print(y.shape)\n",
        "X = df.drop(['researchGroup'], axis=1)\n",
        "print(X.shape)\n",
        "X = pd.get_dummies(data = X, columns = ['subjectSex'] , prefix = ['subjectSex'] , drop_first = True)\n",
        "print(X.shape, '\\n', X.columns)\n",
        "X.head()\n",
        "y = pd.get_dummies(data = y, columns = ['researchGroup'] , prefix = ['researchGroup'] , drop_first = True)\n",
        "print(y.shape, '\\n', y.columns)\n",
        "y.head()\n",
        "print(df_test.columns)\n",
        "y_test = df_test['researchGroup']\n",
        "print(y_test.shape)\n",
        "X_test = df_test.drop(['researchGroup'], axis=1)\n",
        "print(X_test.shape)\n",
        "X_test = pd.get_dummies(data = X_test, columns = ['subjectSex'] , prefix = ['subjectSex'] , drop_first = True)\n",
        "print(X_test.shape, '\\n', X_test.columns)\n",
        "X_test.head()\n",
        "y_test1 = pd.get_dummies(data = y_test, columns = ['researchGroup'] , prefix = ['researchGroup'] , drop_first = True)\n",
        "#print(y_test.shape, '\\n', y.columns)\n",
        "#y.head()\n",
        "lentest = y_test.shape\n",
        "lentest1 = lentest[0] - 1\n",
        "print(lentest1)\n",
        "for i in range(lentest1):\n",
        "  if (y_test[i] == \"CN\"):\n",
        "    y_test[i] = 0\n",
        "  elif (y_test[i] == \"MCI\"):\n",
        "    y_test[i] = 1\n",
        "  else:\n",
        "    y_test[i] = 2\n",
        "print(y_test.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['researchGroup', 'subjectSex', 'MMSCORE', 'GDTOTAL', 'CDGLOBAL',\n",
            "       'NPISCORE', 'FAQTOTAL', 'subjectAge', 'weightKg'],\n",
            "      dtype='object')\n",
            "(1599,)\n",
            "(1599, 8)\n",
            "(1599, 8) \n",
            " Index(['MMSCORE', 'GDTOTAL', 'CDGLOBAL', 'NPISCORE', 'FAQTOTAL', 'subjectAge',\n",
            "       'weightKg', 'subjectSex_M'],\n",
            "      dtype='object')\n",
            "(1599, 2) \n",
            " Index(['['researchGroup']_CN', '['researchGroup']_MCI'], dtype='object')\n",
            "Index(['researchGroup', 'subjectSex', 'MMSCORE', 'GDTOTAL', 'CDGLOBAL',\n",
            "       'NPISCORE', 'FAQTOTAL', 'subjectAge', 'weightKg'],\n",
            "      dtype='object')\n",
            "(688,)\n",
            "(688, 8)\n",
            "(688, 8) \n",
            " Index(['MMSCORE', 'GDTOTAL', 'CDGLOBAL', 'NPISCORE', 'FAQTOTAL', 'subjectAge',\n",
            "       'weightKg', 'subjectSex_M'],\n",
            "      dtype='object')\n",
            "687\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    0\n",
            "Name: researchGroup, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URjO04qQgClC",
        "colab_type": "code",
        "outputId": "20ea2f3a-7457-46f4-f6bd-c82f7bef1c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "from tensorflow.python.layers import base\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "from keras.layers import Dense, Input, Embedding, Reshape, Dropout\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO2phcDKgFLl",
        "colab_type": "code",
        "outputId": "5839363a-380c-4c54-c6c8-c1c1d97c5bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2678
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, auc, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "droprate = 0.4\n",
        "model = Sequential()\n",
        "model.add(Dense(160, input_dim=8, activation='sigmoid'))\n",
        "model.add(Dropout(droprate))\n",
        "model.add(Dense(108, activation='sigmoid'))\n",
        "model.add(Dropout(droprate))\n",
        "#model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X,y, epochs = 75)\n",
        "y_pred = model.predict(X_test)\n",
        "lenPred= y_pred.shape\n",
        "#y_pred = [\"CN\" if x[0] > 0.5 elif x[1] > 0.5 \"MCI\" else \"AD\"  for x in y_pred]\n",
        "y_pred1 = [x for x in y_pred]\n",
        "lenPred1 = lenPred[0] - 1\n",
        "print(lenPred1)\n",
        "for i in range(lenPred1):\n",
        "  if (y_pred[i][0] > 0.5):\n",
        "    y_pred1[i] = 0\n",
        "  elif (y_pred[i][1] > 0.5):\n",
        "    y_pred1[i] = 1\n",
        "  else:\n",
        "    y_pred1[i] = 2\n",
        "score = 0\n",
        "for i in range(lenPred1):\n",
        "  if (y_pred1[i] == y_test[i]):\n",
        "    score = score + 1\n",
        "accuracy = (score/(lenPred1+1))*100\n",
        "print(accuracy)\n",
        "eval = model.evaluate(X_test, y_test1)\n",
        "print(eval)\n",
        "#dnn_score=round(accuracy_score(y_test, y_pred1) * 100,2)\n",
        "#print(Title,'Dataset test accuracy_score',dnn_score)\n",
        "#print(classification_report(y_test_balanced, y_pred))\n",
        " \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1599/1599 [==============================] - 1s 321us/step - loss: 0.6584 - acc: 0.5979\n",
            "Epoch 2/75\n",
            "1599/1599 [==============================] - 0s 72us/step - loss: 0.6456 - acc: 0.5913\n",
            "Epoch 3/75\n",
            "1599/1599 [==============================] - 0s 71us/step - loss: 0.6192 - acc: 0.5997\n",
            "Epoch 4/75\n",
            "1599/1599 [==============================] - 0s 72us/step - loss: 0.5865 - acc: 0.6323\n",
            "Epoch 5/75\n",
            "1599/1599 [==============================] - 0s 69us/step - loss: 0.5633 - acc: 0.6592\n",
            "Epoch 6/75\n",
            "1599/1599 [==============================] - 0s 92us/step - loss: 0.5328 - acc: 0.7073\n",
            "Epoch 7/75\n",
            "1599/1599 [==============================] - 0s 68us/step - loss: 0.5090 - acc: 0.7201\n",
            "Epoch 8/75\n",
            "1599/1599 [==============================] - 0s 69us/step - loss: 0.4949 - acc: 0.7392\n",
            "Epoch 9/75\n",
            "1599/1599 [==============================] - 0s 70us/step - loss: 0.4886 - acc: 0.7339\n",
            "Epoch 10/75\n",
            "1599/1599 [==============================] - 0s 75us/step - loss: 0.4727 - acc: 0.7536\n",
            "Epoch 11/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.4475 - acc: 0.7711\n",
            "Epoch 12/75\n",
            "1599/1599 [==============================] - 0s 71us/step - loss: 0.4384 - acc: 0.7811\n",
            "Epoch 13/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.4227 - acc: 0.8027\n",
            "Epoch 14/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.4028 - acc: 0.8139\n",
            "Epoch 15/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.3984 - acc: 0.8171\n",
            "Epoch 16/75\n",
            "1599/1599 [==============================] - 0s 67us/step - loss: 0.3761 - acc: 0.8330\n",
            "Epoch 17/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.3809 - acc: 0.8258\n",
            "Epoch 18/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.3726 - acc: 0.8346\n",
            "Epoch 19/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.3414 - acc: 0.8518\n",
            "Epoch 20/75\n",
            "1599/1599 [==============================] - 0s 67us/step - loss: 0.3297 - acc: 0.8621\n",
            "Epoch 21/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.3197 - acc: 0.8652\n",
            "Epoch 22/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2964 - acc: 0.8780\n",
            "Epoch 23/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.2975 - acc: 0.8834\n",
            "Epoch 24/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2846 - acc: 0.8881\n",
            "Epoch 25/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2809 - acc: 0.8852\n",
            "Epoch 26/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2906 - acc: 0.8827\n",
            "Epoch 27/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2650 - acc: 0.8977\n",
            "Epoch 28/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2568 - acc: 0.8981\n",
            "Epoch 29/75\n",
            "1599/1599 [==============================] - 0s 69us/step - loss: 0.2439 - acc: 0.9078\n",
            "Epoch 30/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2547 - acc: 0.8971\n",
            "Epoch 31/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.2358 - acc: 0.9137\n",
            "Epoch 32/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2280 - acc: 0.9190\n",
            "Epoch 33/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2278 - acc: 0.9168\n",
            "Epoch 34/75\n",
            "1599/1599 [==============================] - 0s 81us/step - loss: 0.2242 - acc: 0.9174\n",
            "Epoch 35/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2233 - acc: 0.9187\n",
            "Epoch 36/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2251 - acc: 0.9181\n",
            "Epoch 37/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2133 - acc: 0.9281\n",
            "Epoch 38/75\n",
            "1599/1599 [==============================] - 0s 67us/step - loss: 0.2217 - acc: 0.9206\n",
            "Epoch 39/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2313 - acc: 0.9181\n",
            "Epoch 40/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2137 - acc: 0.9271\n",
            "Epoch 41/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2149 - acc: 0.9240\n",
            "Epoch 42/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2078 - acc: 0.9275\n",
            "Epoch 43/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.2116 - acc: 0.9287\n",
            "Epoch 44/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2020 - acc: 0.9325\n",
            "Epoch 45/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2096 - acc: 0.9256\n",
            "Epoch 46/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2034 - acc: 0.9284\n",
            "Epoch 47/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.2132 - acc: 0.9218\n",
            "Epoch 48/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2067 - acc: 0.9293\n",
            "Epoch 49/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.2062 - acc: 0.9306\n",
            "Epoch 50/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1972 - acc: 0.9340\n",
            "Epoch 51/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2020 - acc: 0.9340\n",
            "Epoch 52/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.1971 - acc: 0.9318\n",
            "Epoch 53/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1911 - acc: 0.9350\n",
            "Epoch 54/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.2027 - acc: 0.9346\n",
            "Epoch 55/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1985 - acc: 0.9318\n",
            "Epoch 56/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1952 - acc: 0.9346\n",
            "Epoch 57/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1932 - acc: 0.9375\n",
            "Epoch 58/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1930 - acc: 0.9334\n",
            "Epoch 59/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.1958 - acc: 0.9356\n",
            "Epoch 60/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1938 - acc: 0.9343\n",
            "Epoch 61/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1910 - acc: 0.9312\n",
            "Epoch 62/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1929 - acc: 0.9340\n",
            "Epoch 63/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1937 - acc: 0.9350\n",
            "Epoch 64/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1896 - acc: 0.9384\n",
            "Epoch 65/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.1928 - acc: 0.9353\n",
            "Epoch 66/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1922 - acc: 0.9306\n",
            "Epoch 67/75\n",
            "1599/1599 [==============================] - 0s 65us/step - loss: 0.1908 - acc: 0.9362\n",
            "Epoch 68/75\n",
            "1599/1599 [==============================] - 0s 62us/step - loss: 0.1871 - acc: 0.9359\n",
            "Epoch 69/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.1856 - acc: 0.9381\n",
            "Epoch 70/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.1908 - acc: 0.9362\n",
            "Epoch 71/75\n",
            "1599/1599 [==============================] - 0s 64us/step - loss: 0.1829 - acc: 0.9409\n",
            "Epoch 72/75\n",
            "1599/1599 [==============================] - 0s 63us/step - loss: 0.1901 - acc: 0.9346\n",
            "Epoch 73/75\n",
            "1599/1599 [==============================] - 0s 61us/step - loss: 0.1880 - acc: 0.9387\n",
            "Epoch 74/75\n",
            "1599/1599 [==============================] - 0s 62us/step - loss: 0.1899 - acc: 0.9365\n",
            "Epoch 75/75\n",
            "1599/1599 [==============================] - 0s 66us/step - loss: 0.1912 - acc: 0.9331\n",
            "687\n",
            "82.70348837209302\n",
            "688/688 [==============================] - 0s 180us/step\n",
            "[0.306856679881728, 0.8968023255813954]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}